<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhaowei Cai</title>
  
  <meta name="author" content="Zhaowei Cai">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/ucsd_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhaowei Cai</name>
              </p>
              <p>I am a Senior Applied Scientist with Amazon AGI multimodal team, where I work on computer vision and machine learning. I received my Ph.D. and M.S. degrees from <a href="https://ucsd.edu/">UC San Diego</a>, advised by <a href="http://www.svcl.ucsd.edu/~nuno/">Nuno Vasconcelos</a>. 
              </p>
              <p>
                I have fortunately worked as research intern at Facebook AI Research (FAIR), Micsoft Research Redmond (MSR), IBM T. J. Watson Research, and  Institute of Automation, Chinese Academy of Sciences (CASIA).
              </p>
              <p style="text-align:center">
                <a href="mailto:zwcai513@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=uRrSKVIAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/zhaoweicai">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo_zhaowei.JPG"><img style="width:100%;max-width:100%;border-radius:50%" alt="profile photo" src="images/photo_zhaowei.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <hr>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Recent News</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
              <li>[12/2024] <b><a href="https://www.aboutamazon.com/news/aws/amazon-nova-artificial-intelligence-bedrock-aws">Nova</a> is being launched! Please check it out.</b></li>
              <li>[02/2023] <b><a href="https://arxiv.org/abs/2302.07387">PolyFormer</a> on referring image segmentation was accepted by CVPR 2023!</b></li>
              <li>[01/2023] <b><a href="https://arxiv.org/abs/2208.02131">MaskVLM</a> was accepted by ICLR 2023!</b></li>
              <li>[12/2022] <b>The code of <a href="https://github.com/amazon-science/semi-vit">Semi-ViT</a> has been released!</b></li>
              <li>[10/2022] I will be serving as an Area Chair for CVPR 2023 and ICCV 2023.</li>
              <li>[09/2022] <b>Semi-ViT was accepted by NeurIPS 2022. The codes will be coming soon!</b></li>
              <li>[08/2022] Check out our recent works (<a href="https://arxiv.org/abs/2208.05688">semi-supervised ViT</a> and <a href="https://arxiv.org/abs/2208.02131">masked vision and language modeling</a>).</li>
              <li>[07/2022] Two papers (X-DETR and few-shot detection benchmark) were accepted by ECCV 2022. </li>
              <li>[06/2022] The code of Omni-DETR has been released! Check our <a href="https://github.com/amazon-research/omni-detr">code</a>.</li>
              <li>[03/2022] Omni-DETR was accepted by CVPR 2022. The code is coming soon!</li>
              <li>[06/2021] The code of EMAN has been released! Check our <a href="https://github.com/amazon-research/exponential-moving-average-normalization">code</a>.</li>
              <li>[02/2021] The <a href="https://arxiv.org/pdf/2101.08482.pdf">EMAN</a> paper was accepted by <b>CVPR 2021</b> as <b>Oral</b>.</li>
            </ul>
          </td>
        </tr>
        </tbody></table>
        <hr>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in computer vision and machine learning, especially vision and language understanding, object detection, semi- and self-supervised learning, low-precision neural networks, etc.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>          

        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/MQ-Former.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/pdf/2404.04469">
                    <papertitle>Mixed-Query Transformer: A Unified Image Segmentation Architecture</papertitle>
                </a>
                <br>
                Pei Wang, <u>Zhaowei Cai</u>, Hao Yang, Ashwin Swaminathan, R. Manmatha, Stefano Soatto
                <br>
                arXiv, 2024
                <br>
                <a href="https://arxiv.org/pdf/2404.04469">arxiv</a> /
                <a href="https://dblp.org/rec/journals/corr/abs-2404-04469.html?view=bibtex">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/dparl.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://assets.amazon.science/d5/f8/a6fa596d45d1b259b43c3cb69f22/open-world-dynamic-prompt-and-continual-visual-representation-learning.pdf">
                  <papertitle>Open-World Dynamic Prompt and Continual Visual Representation Learning</papertitle>
                </a>
                <br>
                Youngeun Kim*, Jun Fang*, Qin Zhang, <u>Zhaowei Cai</u>, Yantao Shen, Rahul Duggal, Dripta S. Raychaudhuri, Zhuowen Tu, Yifan Xing, Onkar Dabeer (*equal contribution)
                <br>
                ECCV, 2024
                <br>
                <a href="https://arxiv.org/abs/2409.05312">arxiv</a> /
                <a href="https://dblp.org/rec/conf/eccv/KimFZCSDRTXD24.html?view=bibtex">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/polyformer.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/pdf/2302.07387.pdf">
                    <papertitle>PolyFormer: Referring Image Segmentation as Sequential Polygon Generation</papertitle>
                </a>
                <br>
                Jiang Liu*, Hui Ding*, <u>Zhaowei Cai</u>, Yuting Zhang, Ravi Kumar Satzoda, Vijay Mahadevan, R. Manmatha (*equal contribution)
                <br>
                CVPR, 2023
                <br>
                <a href="https://arxiv.org/abs/2302.07387">arxiv</a> /
                code  /
                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:0n-u_mu9S_gJ:scholar.google.com/&output=citation&scisdr=CgW3jqsmEOCT_gWRZO0:AAGBfm0AAAAAY_2UfO0bxF2u3rx_PB2hi6UOVEmWs7Hy&scisig=AAGBfm0AAAAAY_2UfI0AuirquNMsyjSU7rmXUcE-5Nbn&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/maskvlm.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/pdf/2208.02131.pdf">
                    <papertitle>Masked Vision and Language Modeling for Multi-modal Representation Learning</papertitle>
                </a>
                <br>
                Gukyeong Kwon, <u>Zhaowei Cai</u>, Avinash Ravichandran, Erhan Bas, Rahul Bhotika, Stefano Soatto
                <br>
                ICLR, 2023
                <br>
                <a href="https://arxiv.org/pdf/2208.02131.pdf">arxiv</a> /
                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:g3zbxK8h650J:scholar.google.com/&output=citation&scisdr=CgW3jqsmEOCT_gWXftA:AAGBfm0AAAAAY_2SZtDMkmM16MS1L8FBU_9qwVRH7wUk&scisig=AAGBfm0AAAAAY_2SZgSY0hM3E6NcAkjfiH-PD1_QIT_i&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/semi_vit.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://assets.amazon.science/1a/c8/fef21e8b4a7bae455472f0005413/semi-supervised-vision-transformers-at-scale.pdf">
                    <papertitle>Semi-supervised Vision Transformers at Scale</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u>, Avinash Ravichandran, Paolo Favaro, Manchen Wang, Davide Modolo, Rahul Bhotika, Zhuowen Tu, Stefano Soatto
                <br>
                NeurIPS, 2022
                <br>
                <a href="https://arxiv.org/pdf/2208.05688.pdf">arxiv</a> /
                <a href="https://github.com/amazon-science/semi-vit">code</a>  /
                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:0FzYqh-_vV0J:scholar.google.com/&output=citation&scisdr=CgW3jqsmEOCT_gWXjvE:AAGBfm0AAAAAY_2SlvFCPE5Y-G0hhC17a49bp5-uyfGP&scisig=AAGBfm0AAAAAY_2SluDvkziYHm1Dr4ljJsg8ESiMCCJC&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/xdetr.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://assets.amazon.science/4e/12/77defd3c4c1186cca06fd1528951/x-detr-a-versatile-architecture-for-instance-wise-vision-language-tasks.pdf">
                    <papertitle>X-DETR: A Versatile Architecture for Instance-wise Vision-Language Tasks</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u>, Gukyeong Kwon, Avinash Ravichandran, Erhan Bas, Zhuowen Tu, Rahul Bhotika and Stefano Soatto
                <br>
                ECCV, 2022
                <br>
                <a href="https://arxiv.org/pdf/2204.05626.pdf">arxiv</a> /
                <a href="https://github.com/amazon-science/cross-modal-detr">code</a> /
                <a href="https://dblp.org/rec/conf/eccv/CaiKRBTBS22.html?view=bibtex">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/fsod.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://assets.amazon.science/5e/31/045dac614048a9f89b5d4ed8236d/rethinking-few-shot-object-detection-on-a-multi-domain-benchmark.pdf">
                    <papertitle>Rethinking Few-Shot Object Detection on a Multi-Domain Benchmark</papertitle>
                </a>
                <br>
                Kibok Lee, Hao Yang, Satyaki Chakraborty, <u>Zhaowei Cai</u>, Gurumurthy Swaminathan, Avinash Ravichandran and Onkar Dabeer
                <br>
                ECCV, 2022
                <br>
                <a href="https://arxiv.org/pdf/2207.11169.pdf">arxiv</a> /
                <a href="https://github.com/amazon-science/few-shot-object-detection-benchmark">code</a> /
                <a href="https://dblp.org/rec/conf/eccv/LeeYCCSRD22.html?view=bibtex">bibtex</a>
            </td>
        </tr>
          
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/omni_detr.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://assets.amazon.science/91/3c/ac87e7dd44789a62e03b2230e0ed/omni-detr-omni-supervised-object-detection-with-transformers.pdf">
                    <papertitle>Omni-DETR: Omni-Supervised Object Detection with Transformers</papertitle>
                </a>
                <br>
                Pei Wang, <u>Zhaowei Cai</u>, Hao Yang, Gurumurthy Swaminathan, Nuno Vasconcelos, Bernt Schiele and Stefano Soatto
                <br>
                <em>CVPR</em>, 2022
                <br>
                <a href="https://arxiv.org/pdf/2203.16089.pdf">arxiv</a> /
                <a href="https://github.com/amazon-science/omni-detr">code</a> /
                <a href="https://dblp.org/rec/conf/cvpr/WangCYSVSS22.html?view=bibtex">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/cna.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/pdf/2201.01922.pdf">
                    <papertitle>Contrastive Neighborhood Alignment</papertitle>
                </a>
                <br>
                Pengkai Zhu, <u>Zhaowei Cai</u>, Yuanjun Xiong, Zhuowen Tu, Luis Goncalves, Vijay Mahadevan and Stefano Soatto
                <br>
                arXiv, 2022
                <br>
                <a href="https://arxiv.org/pdf/2201.01922.pdf">arxiv</a> /
                <a href="https://dblp.org/rec/journals/corr/abs-2201-01922.html?view=bibtex">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/book.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://www.elsevier.com/books/advanced-methods-and-deep-learning-in-computer-vision/davies/978-0-12-822109-9">
                    <papertitle>Advanced Methods for Robust Object Detection</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u> and Nuno Vasconcelos
                <br>
                book chapter of Advanced Methods and Deep Learning in Computer Vision, 2021
                <br>
                <a href="https://www.elsevier.com/books/advanced-methods-and-deep-learning-in-computer-vision/davies/978-0-12-822109-9">link</a> /
                <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:w1L6skCEvlMJ:scholar.google.com/&output=citation&scisdr=CgVNiM8rEOCT_70AudI:AAGBfm0AAAAAYkUFodKZX7BAc600ILZKL1X3lDD5BWt-&scisig=AAGBfm0AAAAAYkUFoRGMEG3VGeA0N_aA1rCXnBpGfjHX&scisf=4&ct=citation&cd=-1&hl=en">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/eman.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://assets.amazon.science/f0/3d/2080880e466c9b4d02bd3bc2d16b/exponential-moving-average-normalization-for-self-supervised-learning.pdf">
                    <papertitle>Exponential Moving Average Normalization for Self-supervised and Semi-supervised Learning</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u>, Avinash Ravichandran, Subhransu Maji, Charless Fowlkes, Zhuowen Tu and Stefano Soatto
                <br>
                <em>CVPR</em>, 2021 (<b>Oral</b>)
                <br>
                <a href="https://arxiv.org/pdf/2101.08482.pdf">arxiv</a> /
                <a href="https://github.com/amazon-science/exponential-moving-average-normalization">code</a> /
                <a href="https://dblp.org/rec/conf/cvpr/CaiRMFTS21.html?view=bibtex">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/edmips.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://www.svcl.ucsd.edu/publications/conference/2020/cvpr/EdMIPS.pdf">
                    <papertitle>Rethinking Differentiable Search for Mixed-Precision Neural Networks</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u> and Nuno Vasconcelos
                <br>
                <em>CVPR</em>, 2020
                <br>
                <a href="https://arxiv.org/pdf/2004.05795.pdf">arxiv</a> /
                <a href="https://github.com/zhaoweicai/EdMIPS">code</a> /
                <a href="https://dblp.org/rec/bibtex/conf/cvpr/CaiV20">bibtex</a>
            </td>
        </tr>
    
        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/detrac.jpg' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://arxiv.org/pdf/1511.04136.pdf">
                    <papertitle>UA-DETRAC: A New Benchmark and Protocol for Multi-Object Detection and Tracking</papertitle>
                </a>
                <br>
                Longyin Wen, Dawei Du, <u>Zhaowei Cai</u>, Zhen Lei, Ming-Ching Chang, Honggang Qi, Jongwoo Lim, Ming-Hsuan Yang and Siwei Lyu
                <br>
                <em>CVIU</em>, 2020
                <br>
                <a href="https://arxiv.org/abs/1511.04136">arxiv</a> /
                <a href="http://detrac-db.rit.albany.edu/">project</a> /
                <a href="https://dblp.org/rec/bibtex/journals/cviu/WenDCLCQLYL20">bibtex</a>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/universal.jpg' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Towards_Universal_Object_Detection_by_Domain_Attention_CVPR_2019_paper.pdf">
                    <papertitle>Towards Universal Object Detection by Domain Attention</papertitle>
                </a>
                <br>
                Xudong Wang, <u>Zhaowei Cai</u>, Dashan Gao and Nuno Vasconcelos
                <br>
                <em>CVPR</em>, 2019
                <br>
                <a href="https://arxiv.org/abs/1904.04402">arxiv</a> /
                <a href="http://www.svcl.ucsd.edu/projects/universal-detection/">project</a> /
                <a href="https://github.com/frank-xwang/towards-universal-object-detection">code</a> /
                <a href="https://dblp.org/rec/bibtex/conf/cvpr/0007CGV19">bibtex</a>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/cascade_rcnn.jpg' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://www.svcl.ucsd.edu/publications/journal/2019/cascadercnn_pami.pdf">
                    <papertitle>Cascade R-CNN: High Quality Object Detection and Instance Segmentation</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u> and Nuno Vasconcelos
                <br>
                <em>T-PAMI</em>, 2019
                <br>
                <a href="https://arxiv.org/abs/1906.09756">arxiv</a> /
                <a href="http://www.svcl.ucsd.edu/projects/cascade-rcnn/">project</a> /
                <a href="https://github.com/zhaoweicai/Detectron-Cascade-RCNN">code</a> /
                <a href="http://www.svcl.ucsd.edu/projects/cascade-rcnn/cascadercnn_pami.bib">bibtex</a>
                  
                <p>
                <a href="http://www.svcl.ucsd.edu/publications/conference/2018/cvpr/cascade-rcnn.pdf">
                    <papertitle>Cascade R-CNN: Delving into High Quality Object Detection</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u> and Nuno Vasconcelos
                <br>
                <em>CVPR</em>, 2018 (<b>Spotlight</b>)
                <br>
                <a href="https://arxiv.org/abs/1712.00726">arxiv</a> /
                <a href="http://www.svcl.ucsd.edu/projects/cascade-rcnn/">project</a> /
                <a href="https://github.com/zhaoweicai/cascade-rcnn">code</a> /
                <a href="https://dblp.org/rec/bibtex/conf/cvpr/CaiV18">bibtex</a>
            </td>
        </tr>  

        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/hwgq.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://www.svcl.ucsd.edu/publications/conference/2017/cvpr/hwgq.pdf">
                    <papertitle>Deep Learning with Low Precision by Half-wave Gaussian Quantization</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u>, Xiaodong He, Jian Sun and Nuno Vasconcelos
                <br>
                <em>CVPR</em>, 2017 (<b>Spotlight</b>)
                <br>
                <a href="https://arxiv.org/abs/1702.00953">arxiv</a> /
                <a href="http://www.svcl.ucsd.edu/projects/hwgq/">project</a> /
                <a href="https://github.com/zhaoweicai/hwgq">code</a> /
                <a href="https://dblp.org/rec/bibtex/journals/corr/abs-1904-04402">bibtex</a>
            </td>
        </tr>   

        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/mscnn.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://www.svcl.ucsd.edu/publications/conference/2016/mscnn/mscnn.pdf">
                    <papertitle>A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u>, Quanfu Fan, Rogerio S. Feris and Nuno Vasconcelos
                <br>
                <em>ECCV</em>, 2016
                <br>
                <a href="https://arxiv.org/abs/1607.07155">arxiv</a> /
                <a href="http://www.svcl.ucsd.edu/projects/mscnn/">project</a> /
                <a href="https://github.com/zhaoweicai/mscnn">code</a> /
                <a href="http://dblp.dagstuhl.de/rec/bibtex/conf/eccv/CaiFFV16">bibtex</a>
            </td>
        </tr>  

        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/compact.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://www.svcl.ucsd.edu/publications/journal/2019/compact_pami.pdf">
                    <papertitle>Learning Complexity-Aware Cascades for Pedestrian Detection</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u>, Mohammad Saberian and Nuno Vasconcelos
                <br>
                <em>T-PAMI</em>, 2019
                <br>
                  
                <p>
                <a href="http://www.svcl.ucsd.edu/publications/conference/2015/CompACT/CompACT.pdf">
                    <papertitle>Learning Complexity-Aware Cascades for Deep Pedestrian Detection</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u>, Mohammad Saberian and Nuno Vasconcelos
                <br>
                <em>ICCV</em>, 2015 (<b>Oral</b>)
                <br>
                <a href="https://arxiv.org/abs/1712.00726">arxiv</a> /
                <a href="https://www.youtube.com/watch?v=2_TIZ9mPOwo">demo</a> /
                <a href="http://dblp.uni-trier.de/rec/bibtex/conf/iccv/CaiSV15">bibtex</a>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/dgt.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://www.svcl.ucsd.edu/publications/journal/2014/DGT-TIP.pdf">
                    <papertitle>Robust Deformable and Occluded Object Tracking with Dynamic Graph</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u>, Longyin Wen, Zhen Lei, Nuno Vasconcelos and Stan Z. Li
                <br>
                <em>T-IP</em>, 2014
                <br>
                <a href="https://sites.google.com/site/zhaoweicai1989/dgt">project</a> /
                <a href="http://dblp.uni-trier.de/rec/bibtex/journals/tip/CaiWLVL14">bibtex</a>
                  
                <p>
                <a href="http://www.svcl.ucsd.edu/~zwcai/publications/accv12_dgt.pdf">
                    <papertitle>Structured Visual Tracking with Dynamic Graph</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u> Longyin Wen, Jianwei Yang, Zhen Lei and Stan Z. Li
                <br>
                <em>ACCV</em>, 2012
                <br>
                <a href="http://dblp.uni-trier.de/rec/bibtex/conf/accv/CaiWYLL12">bibtex</a>
            </td>
        </tr>  

        <tr>
            <td style="padding:20px;width:35%;vertical-align:center">
                <img src='images/stt.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://www.svcl.ucsd.edu/~zwcai/publications/tip14_stt.pdf">
                    <papertitle>Robust Online Learned Spatio-Temporal Context Model for Visual Tracking</papertitle>
                </a>
                <br>
                Longyin Wen, <u>Zhaowei Cai</u>, Zhen Lei, Dong Yi and Stan Z. Li
                <br>
                <em>T-IP</em>, 2014
                <br>
                <a href="http://dblp.uni-trier.de/rec/bibtex/journals/tip/WenCLYL14">bibtex</a>
                  
                <p>
                <a href="http://www.svcl.ucsd.edu/~zwcai/publications/eccv12_stt.pdf">
                    <papertitle>Online Spatio-Temporal Structural Context Learning for Visual Tracking</papertitle>
                </a>
                <br>
                Longyin Wen, <u>Zhaowei Cai</u>, Zhen Lei, Dong Yi and Stan Z. Li
                <br>
                <em>ECCV</em>, 2012
                <br>
                <a href="http://dblp.uni-trier.de/rec/bibtex/conf/eccv/WenCLYL12">bibtex</a>
            </td>
        </tr> 

        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/face.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="https://ieeexplore.ieee.org/document/6553730">
                    <papertitle>Person-Specific Face Tracking with Online Recognition</papertitle>
                </a>
                <br>
                <u>Zhaowei Cai</u>,  Longyin Wen, Dong Cao, Zhen Lei, Dong Yi and Stan Z. Li
                <br>
                <em>FG</em>, 2013
                <br>
                <a href="http://dblp.uni-trier.de/rec/bibtex/conf/fgr/CaiWCLYL13">bibtex</a>
            </td>
        </tr> 

        <tr>
            <td style="padding:20px;width:35%;vertical-align:top">
                <img src='images/reflection.png' width="250"></div>
                    </div>
                    </td>
            <td width="75%" valign="middle">
                <p>
                <a href="http://www.svcl.ucsd.edu/~zwcai/publications/accv12_yang.pdf">
                    <papertitle>A New Projection Space for Separation of Specular and Diffuse Reflection Components in Color Images</papertitle>
                </a>
                <br>
                Jianwei Yang, <u>Zhaowei Cai</u>, Zhen Lei, Dong Yi and Stan Z. Li
                <br>
                <em>ACCV</em>, 2012
                <br>
                <a href="http://dblp.uni-trier.de/rec/bibtex/conf/accv/YangCWLGL12">bibtex</a>
            </td>
        </tr> 


        </tbody></table>
        <hr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Service</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
              <li>Area Chair: ICML25, CVPR25, ICLR25, NeurIPS24, EMNLP24, CVPR24, ICCV23, CVPR23</li>
              <li>Workshop co-organizer of <a href="https://eccv20-adv-workshop.github.io/">Adversarial Robustness in the Real World</a> in ECCV 2020.</li>
              <li>Journal Reviewer: T-PAMI, IJCV, T-IP, CVIU, T-MM, PR, T-CSVT, T-ITS, T-Cybernetics</li>
              <li>Conference Reviewer: ECCV24, NeurIPS23, NeurIPS22, ICML22, CVPR22, ICLR22, NeurIPS21, ICCV21, ICML21, CVPR21, ICLR21, NeurIPS20, ICML20, ECCV20, CVPR20, NeurIPS19, ICML19, ICCV19, CVPR19 (outstanding reviewer), NIPS18, ECCV18, ICML18, CVPR18, NIPS17, ICCV17, CVPR17</li>
            </ul>
          </td>
        </tr>
        </tbody></table>
        <hr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Talks</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
              <li>Invited talk at UCSC AI seminar: Image/Object/Mask-level Vision and Language Understanding.</li>
              <li>Invited talk at UCSB NLP group: Pushing the Limits of Object Detection.</li>
              <li>Invited talk at UCSB: Low-precision Neural Networks.</li>
              <li>Guest lecture at UCSC: Exponential Moving Average Normalization for Self- and Semi- Supervised Learning.</li>
            </ul>
          </td>
        </tr>
        </tbody></table>
        <hr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">template credit to <a href="https://jonbarron.info/">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
